---
title: |
  | Homework 1: Simple Linear Regression an Logistic Regression
author: "<MELTEM AKKOCA (31598286002)>"
date: "Last compiled on `r format(Sys.time(), '%d %B, %Y')`"
output: 
  pdf_document:
    fig_width: 6 
    fig_height: 4 
    number_sections: yes
    toc: yes
---


```{r setup, include=FALSE, echo=F, warning=F, message=F}
knitr::opts_chunk$set(echo = TRUE)
```

# Part 1: Simple Linear Regression

Exam grades and weekly spent time on self study $x$ (in hours) of 14 statistics students are given in the following table. 

| Self study | 25.0 | 26.2 | 24.9 | 23.7 | 22.8 | 24.6 | 23.6 | 23.0 | 22.5 | 26.2 | 25.8 | 24.0 | 22.1 | 21.7 |
|---------------|------|------|------|------|------|------|------|------|------|------|------|------|------|------|
| Exam Grades      |   63 |   53 |   52 |   46 |   34 |   47 |   43 |   37 |   40 |   45 |   53 |   42 |   32 |   49 |


1. Create a data frame in `R` with the above data. Plot the data with the weekly spent time on self study in the $x$-axis and exam grades on the $y$-axis (You should include labels for your axes and a title for the plot)

2. Obtain the least squares regression line of exam grades on weekly spent time on self study. Interpret your model result (Using the whole data set)

3. Fit the linear model after partitioning your data set into training and testing (round the number of observations when it is necessary). After fitting the model, compare your parameter estimates with the model result in Question 2. Then, make predictions on testing data and compare with the original observations. 

4. Using the `plot` command, comment on the validity of the assumption of the model that you fit in Question 3 (Note before using the `plot` command you may wish to specify a 2x2 graphics window using `par(mfrow = c(2, 2))`).

5. Calculate a $95\%$ confidence interval for the slope regression parameter for the last model you fit in Question 3. (Note that the number of degrees of freedom should be obtained from the `R` output). For this you can use a built-in function in R

# Part 1: Solution

Use the given R-code chunk below to make your calculations and summarize your result thereafter by adding comments on it, 

- MAKE SURE THAT ALL NECESSARY PACKAGES ARE ALREADY INSTALLED and READY TO USE 

- You can use as many as Rcode chunks you want. In the final output, both Rcodes and your ouputs including your comments should appear in an order

```{r}
# FOR REPRODUCIBILITY
set.seed(86002)
# ALERT: YOU NEED TO USE YOUR STUDENT NUMBER LAST 5 DIGITS 
# HERE instead of 442 MAKE SURE THAT YOU CHANGED 
# BEFORE STARTING TO YOUR ANALYSIS



```

This is an example of simple linear regression. I only have one independent variable and one dependent variable.Independent variable is self_study and dependent variable is exam grade.Self Study and Exam grades are my observations in vectors. I created a data frame with these  datas. 



```{r}
# 1. Create a data frame in `R` with the above data. Plot the data with the weekly 
#spent time on self study in the $x$-axis and exam grades on the $y$-axis 
#(You should include labels for your axes and a title for the plot)

#I am trying to explain exam grades with respect to self study that's why, self 
#study is my predictor and exam grades are my response

Self_Study = c(25.0, 26.2, 24.9, 23.7, 22.8, 24.6, 23.6, 23.0, 22.5, 26.2, 25.8, 24.0, 22.1, 21.7)

Exam_Grades = c(63, 53, 52, 46, 34, 47, 43, 37, 40, 45, 53, 42, 32, 49)

data_frame = data.frame(Self_Study,Exam_Grades,stringsAsFactors = FALSE)


#this function obtain a plot which contains y axis is exam grades and x axis is
#weekly spent time on self study and plot name is Scatterplot of Self_Study and
#Exam_Grades
plot(data_frame$Self_Study, data_frame$Exam_Grades,
     # Modify title and axis labels
     xlab = "Self_Study",
     ylab = "Exam_Grades",
     main="Scatterplot of Self_Study and Exam_Grades")

```



```{r}
### FIT LSRL ####

#2. Obtain the least squares regression line of exam grades on weekly spent time
#on self study. Interpret your model result (Using the whole data set)


#first looking at the data_frame information
#with this str function we learned that 14 obs. of  2 variables and all of them
#numerical variables.
str(data_frame)
head(data_frame)
#looking for all info about data min,max,mean etc.
summary(data_frame)

# cor function is the correlation coefficient, and i see that higher values 
#obviously
cor(data_frame[, c("Self_Study","Exam_Grades")])

#to draw a histogram 
hist(data_frame$Exam_Grades)

#-----------------------------------------

#since lm function extract exam grades and self study from original data set,
#we don't need to write like this data_frame$Exam_Grades. We assigned output of
#the lm function to an object.
lm.fit <- lm(formula = Exam_Grades ~ Self_Study, data = data_frame)


# To understand the relationship between two variables, its plot of the data like 
#above
#by looking at the plot, we can say that there is a kind of linear relationship
plot(data_frame[, c("Self_Study","Exam_Grades")])

#same scatterplot with the previous, but with the least-squares regression line
#“fit” to the data to describe exam grades by self study
abline(lm.fit, col="red")

summary(lm.fit)



#if i want to make a prediction, my new value should be lying between this two 
#output value 21.7 and 26.2
#range(data_frame$Self_Study)

#we can understand our estimation significant or not simply evaluating p values
#stars illustrates differenet significant levels if we find bigger p values we 
#need to be suspicious for model reliability
#final p value is overall significant level of our linear model




```
I can say that;
Explanatory- Predictor variable : Self_Study
Response variable : Exam_Grades

I can use histogram function to determine and to check the dependent(Exam Grades) variable follows a normal distribution. I see that my histogram follows a roughly bell-shaped curve that's why, it is following the normal distribution. That's why i can go into progress with linear regression.

By looking at the plot we can say that the relationship between dependent( Exam Grades ) and independent( Self Study ) variable is Linear, Positive and Weak.

I obtain significant parameter estimate but at the same time r squared value (0.3958) smaller than trashold(widely considered as 0.5)

The slope explain that how much increase there will be in the y axis for one unit increase in x axis thats why in our example, for every additional self study, exam grade will be 3.531 more points
In our example value of y intercept i mean, for 0 hour self study , the exam grade should be -39.347, it does not make sense.

If I look at the p value the corresponding p-value is 0.0159, which is statistically significant at an alpha level of 0.05.

This tells us that that the average change in exam score for each additional weekly spent time is statistically significantly different than zero.


```{r}
#3. Fit the linear model after partitioning your data set into training and 
#testing (round the number of observations when it is necessary). After fitting 
#the model, compare your parameter estimates with the model result in Question 
#2. Then, make predictions on testing data and compare with the original 
#observations. 


#80% (11) should go the training subset,and rest should belong to the testing subset
sample.size <- floor(0.80 * nrow(data_frame)) # %80 for training, %20 for testing

#we are sampling from the whole set of data to create the index for training
train.index <- sample(seq_len(nrow(data_frame)), size = sample.size)

# Partitioning on training and testing
#in train.index, we are picking up  some of the observations for trainig set
train <- data_frame[train.index, ]
#it is just dropping spesific rows , this is our testing data
test <- data_frame[-train.index, ]

#dimension of the train and test data 
dim(train)
dim(test)
# MODEL BUILDING
# Simple linear regression 
#estimations are diffrent but they are really close to each other, 
#according to which observations picking up  for the training set,the model 
#output will be change a little bit
lm.fit = lm(formula = Exam_Grades ~ Self_Study, data = train) 
summary(lm.fit) 


# PREDICTION : Use the testing data
class(lm.fit)

# Make prediction on training data because we obtain lm on training data to 
#lm fit
predict(lm.fit)
# Make predictions on testing only, newdata set  (testing subset playing a role
#new observation for the fitted model)
predict_data_frame <- predict(lm.fit, newdata = test)
#the results are my predictions
head(predict_data_frame)
#these results are true observations under the test data
head(test$Exam_Grades)



# Looking at RMSE basically
# difference between original and predicted values
MSE_fit <- mean((test$Exam_Grades - predict_data_frame)^2)
MSE_fit

#error rate by the sqrt of MSE
RMSE_fit <- sqrt(MSE_fit)
RMSE_fit

cor(predict_data_frame, test$Exam_Grades)^2

```




```{r}

#4. Using the `plot` command, comment on the validity of the assumption of the 
#model that you fit in Question 3 (Note before using the `plot` command 
#you may wish to specify a 2x2 graphics window using `par(mfrow = c(2, 2))`).

#partition of the window 2 row and 2 column
par(mfrow = c(2, 2))
#creates for different plots(residuals,Q-Q etc.)
plot(lm.fit)
  

```
residuals should following normal distibution, red line should be approximately horizontal at zero. in our example, the linear assumption is not met, because the red line is not flatting on the zero at some points. 

normal Q-Q plot, realize that upper tail, there is a kind of violation when we compare with the lower tail from the normal assumption. The points should be follow the diagonal line.

scale location,we need to see almost horizantal line, but there is no horizontal line in our example

residuals vs leverage, extreme values that might influence the regression results  coming from the observation which could be out of the range.


```{r}
#5. Calculate a $95\%$ confidence interval for the slope regression parameter 
#for the last model you fit in Question 3. (Note that the number of degrees of 
#freedom should be obtained from the `R` output). For this you can use a built-in function in R

confint(lm.fit, level=0.95) 

```
I made calculation because of the confidence interval with using confint() function.

# Part 2: Logistic Regression

Consider the available example data set below

```{r}
# install.packages("mlbench")
library(mlbench)
data(BreastCancer)

summary(BreastCancer)
# You can check the details here
# https://www.rdocumentation.org/packages/mlbench/versions/2.1-3/topics/BreastCancer
```

1. Convert your Class variable into a numerical one since you have two classes (benign malignant) you can make it one of them as 0 and the other one is 1

2. Fit a logistic regression model to classify **Class** using Mitoses (DO NOT FORGET TO PARTITION YOUR DATA INTO TRAINING AND TESTING DATA SETS, DO NOT FORGET THAT THIS DATA SET INCLUDES QUALITATIVE PREDICTORS !)

3. Make predictions and compare with the true observations (using TEST DATA SET). Calculate and intepret the Confusion Matrix results


4. Fit a multiple logistic regression to classify **Class** by using more than one predictor

5. Compare simple logistic and multiple logistic regression models using F1-score to make a decision on the best model. Why the overall accuracy is not enough as a performance measure ? Explain shortly 

# Part 2: Solution

Use the given R-code chunk below to make your calculations and summarize your result thereafter by adding comments on it, 

- MAKE SURE THAT ALL NECESSARY PACKAGES ARE ALREADY INSTALLED and READY TO USE 

- You can use as many as Rcode chunks you want. In the final output, both Rcodes and your ouputs including your comments should appear in an order

```{r}
# 1. Convert your Class variable into a numerical one since you have two classes 
#(benign malignant) you can make it one of them as 0 and the other one is 1

#provides access to the levels attribute of a variable. The first form 
#returns the value of the levels of its argument and the second sets the attribute.
levels(BreastCancer$Class) <- c(1,0)  
# Benign = 1, malignant = 0

head(BreastCancer)

```


```{r}
#2. Fit a logistic regression model to classify **Class** using Mitoses 
#(DO NOT FORGET TO PARTITION YOUR DATA INTO TRAINING AND TESTING DATA SETS,
#DO NOT FORGET THAT THIS DATA SET INCLUDES QUALITATIVE PREDICTORS !)



#BreastCancer data is divided into 80% training and %20 testing test
BC_idx = sample(nrow(BreastCancer), 0.8 * nrow(BreastCancer))
BC_idx
#---------------------------
# Training data set
BC_train = BreastCancer[BC_idx, ]
# Testing data set
BC_test = BreastCancer[-BC_idx, ]

#install glm2 library
library("glm2")
#fitting logistic reg. model while using mitosis a predictor
BC_glm = glm(Class~Mitoses, data=BC_train, family="binomial")





summary(BC_glm)

```
I divided into data set with (%80 training and %20 test) two parts training and test.
My predictor is Mitosis and i gained the data from the trainig data while using for my logistic regression model 





```{r}
#3. Make predictions and compare with the true observations (using TEST DATA SET). 
#Calculate and intepret the Confusion Matrix results

#installing the necessery package and call it
library(caret)
#to create prediction
predicted_values <- predict(BC_glm,type="response",newdata = BC_test)
#to make classification
BC_glm_predictor = ifelse(predicted_values >= 0.5,1,0)
                           
#creating confusion matrix
confusion_matrix_test = confusionMatrix(as.factor(BC_glm_predictor),as.factor(BC_test$Class))

confusion_matrix_test

```
True positive (TP) (in our model it is 5 times) is the number of true results when the actual observation is positive.

False positive (FP) (in our model it is 27 times) is the number of incorrect predictions when the actual observation is positive.

True negative (TN) (in our model it is 24 times) is the number of true predictions when the observation is negative.

False negative (FN) (in our model it is 84 times)is the number of incorrect predictions when the observation is negative.


```{r}
#4. Fit a multiple logistic regression to classify **Class** by using more than one predictor

BC_glm_multiple <- glm(Class~Cl.thickness +Epith.c.size, data=BC_train,family="binomial")

predicted_values_multiple <- predict(BC_glm_multiple,type="response",newdata=BC_test)
BC_glm_multiple_predictor = ifelse(predicted_values_multiple >= 0.5,1,0)

#creating confusion matrix
confusion_matrix_test_multiple = confusionMatrix(as.factor(BC_glm_multiple_predictor),as.factor(BC_test$Class))

confusion_matrix_test_multiple 

```

I took Cl.thickness and Epith.c.size as two predictors because of multiple predictors. Then also, I created the confusion matrix with these predictors and my newdata=BC_test. And I compare with accuracy of the one predictor and multiple predictor, i can say that accuracy level of simple logistic regression is better than multiple.

True positive (TP) (in our model it is 8 times) is the number of true results when the actual observation is positive.

False positive (FP) (in our model it is 81 times) is the number of incorrect predictions when the actual observation is positive.

True negative (TN) (in our model it is 2 times) is the number of true predictions when the observation is negative.

False negative (FN) (in our model it is 49 times)is the number of incorrect predictions when the observation is negative.


```{r}
#5. Compare simple logistic and multiple logistic regression models using F1-score 
#to make a decision on the best model. Why the overall accuracy is not enough as 
#a performance measure ? Explain shortly


library(MLmetrics)

#f1 score calculations
F1_Score(as.factor(BC_glm_predictor),as.factor(BC_test$Class),positive ="0")

F1_Score(as.factor(BC_glm_multiple_predictor),as.factor(BC_test$Class),positive="0")




```


I have obtain less F1_score with multiple predictor than  F1_score with one predictor.That's mean that model will obtain a low F1 score and it's both Precision and Recall are low. F1_score with one predictor are better than  F1_score with multiple predictor. Because all of this reasons i can say in my data samples that simple logistic regression is better than the multiple logistic regression because our F1 score for multiple logistic regresssion is lower than simple logistic regression.

F1 Score value shows us the harmonic mean of (Precision) and (Recall) values.Our F1 scores were also low because both of our values were low.

We can’t directly say accuracy is poor measure to evaluate. When the data is balanced accuracy is a good measure of evaluating our model. In other hand if data is imbalanced then accuracy is not a correct measure of evaluation.


Actually i can say that my observation and my data give a little bit bad value, i really get confused and force to comment on it.
# References 

Give a list of the available sources that you use while preparing your home-work
(If you use other resources, you can make a list here for checking & reproducibility). 

http://www.sthda.com/english/articles/39-regression-model-diagnostics/161-linear-regression-assumptions-and-diagnostics-in-r-essentials/

https://rstudio-pubs-static.s3.amazonaws.com/199692_d02c8f7b352e4ec1b85544432ac28896.html

https://medium.com/@KrishnaRaj_Parthasarathy/ml-classification-why-accuracy-is-not-a-best-measure-for-assessing-ceeb964ae47c

https://medium.com/@gulcanogundur/do%C4%9Fruluk-accuracy-kesinlik-precision-duyarl%C4%B1l%C4%B1k-recall-ya-da-f1-score-300c925feb38

https://www.turing.com/kb/how-to-plot-confusion-matrix



